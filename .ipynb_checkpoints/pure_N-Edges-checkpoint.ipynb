{
 "cells": [
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Importing"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import ipyrad.analysis as ipa\n",
    "import ipcoal\n",
    "import toytree\n",
    "import toyplot\n",
    "import pandas as pd\n",
    "from ipyrad.analysis.baba21 import Drawing\n",
    "import random\n",
    "import os\n",
    "import ipyparallel as ipp"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Define functions"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "import random\n",
    "\n",
    "\n",
    "def generate_tests_from_names(sources, targets_raw, outgroup, no_repeat=True):\n",
    "    \n",
    "    if type(sources) is not list:\n",
    "        sources = [sources]\n",
    "    \n",
    "    if type(outgroup) is not list:\n",
    "        outgroup = [outgroup]\n",
    "    \n",
    "    #Declare empty result\n",
    "    tests =[]\n",
    "    \n",
    "    for source in sources:\n",
    "        #If in sources are the outgroup skip it\n",
    "        if source in outgroup:\n",
    "            continue\n",
    "        \n",
    "        \n",
    "        #New unlinked targets list every loop\n",
    "        targets = targets_raw.copy()\n",
    "            \n",
    "        #Remove source and outgroups in case they are repeated in the targets list\n",
    "        if source in targets:\n",
    "            targets.remove(source)\n",
    "        for i in outgroup:\n",
    "            if i in targets:\n",
    "                targets.remove(i) \n",
    "\n",
    "        #declare empty lists \n",
    "        included = []\n",
    "        \n",
    "\n",
    "        #Iterate over all targets\n",
    "        for i, _ in enumerate(targets):\n",
    "            #empty temp p variables\n",
    "            p1 = [] \n",
    "            p2 = []\n",
    "\n",
    "           #only do following if target was not already used (not in included)\n",
    "            if targets[i] not in included:\n",
    "                #use the first target as p1\n",
    "                p1 = [targets[i]]\n",
    "                #mark it is used appending to the list\n",
    "                if no_repeat: included.append(targets[i])\n",
    "                #avoid out of boundary errors\n",
    "                if i < len(targets)-1:\n",
    "                    #use the next target as p2\n",
    "                    if targets[i+1] not in included:\n",
    "                        p2 = [targets[i+1]]\n",
    "                        #mask it as used\n",
    "                        if no_repeat: included.append(targets[i+1])\n",
    "                else:\n",
    "                    #in case it is the last element (for odd number of targets, use a random one (but the current) as p2)\n",
    "                    targets.remove(targets[i])\n",
    "                    p2 =  [random.choice(targets)]\n",
    "\n",
    "                #append test to the return list\n",
    "                tests.append({'p1': p1, 'p2': p2, 'p3': [source], 'p4': outgroup})\n",
    "                \n",
    "    return tests #return list of dictionaries with every test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "def get_significant_donee(df_result, test):\n",
    "    if df_result[\"D\"].values[0] > 0:\n",
    "            significative_donee = test[\"p2\"]\n",
    "    elif df_result[\"D\"].values[0] < 0:\n",
    "        significative_donee = test[\"p1\"]\n",
    "    return significative_donee"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "def run_tests_depuring(data, tests, tree, zscoreTH=2.5, distant=True, verbose=False):\n",
    "#v4\n",
    "    tests_performed_dict = {}\n",
    "    truepositives_network = []\n",
    "    falsepositives_network = []\n",
    "    n_tests = 0\n",
    "    n_fp = 0\n",
    "    \n",
    "    #Do test by test\n",
    "    for i in tests:\n",
    "        if verbose: print(\"\\n*** Testing:\", i, \"***\")\n",
    "        donor = i[\"p3\"]\n",
    "        outgroup = i[\"p4\"]\n",
    "        donees = [*i[\"p1\"], *i[\"p2\"]]\n",
    "        \n",
    "        \n",
    "        #Any test is saved in a dict with the significative donee as value by donors, here I create donor dict\n",
    "        if str(*donor) not in tests_performed_dict:\n",
    "            tests_performed_dict[str(*donor)] = {}\n",
    "        \n",
    "        \n",
    "        #Check if the test was already performed, get the significative donee and continue to other test\n",
    "        if str(sorted(donees)) in tests_performed_dict[str(*donor)].keys():\n",
    "            if verbose: print(\"test already performed (skipped) previous significative donee: \", tests_performed_dict[str(*donor)][str(sorted(donees))])\n",
    "            continue\n",
    "        \n",
    "\n",
    "        #Save DF of resulst\n",
    "        n_tests += 1\n",
    "        try:\n",
    "            df_result = data.run_test(i, nboots=100, quiet=True)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "\n",
    "       \n",
    "        \n",
    "        \n",
    "        #If test is significant\n",
    "        if df_result[\"Z\"].values[0] > zscoreTH:\n",
    "\n",
    "            #Get if ABBA or BABA is the significant usind D\n",
    "            significative_donee = get_significant_donee(df_result, i)\n",
    "\n",
    "            #Update tests dict\n",
    "            tests_performed_dict[str(*donor)][str(sorted(donees))] = str(*significative_donee)\n",
    "\n",
    "\n",
    "            ## Check all phylo neighborhood to see if the significant is due to shared ancestry\n",
    "\n",
    "            #Get sisters in the tree of significant donee\n",
    "            sisters_significant_donee = tree.get_tip_labels(tree.idx_dict[tree.get_mrca_idx_from_tip_labels(significative_donee)].get_ancestors()[0].idx) \n",
    "\n",
    "            #Remove donor, sig_donee and outgroup from sisters list to avoid test donor-donor or donor-outgroup, donee-donee\n",
    "            for ele in donor:\n",
    "                if ele in sisters_significant_donee:\n",
    "                    sisters_significant_donee.remove(ele)        \n",
    "            for ele in outgroup:\n",
    "                if ele in sisters_significant_donee:\n",
    "                    sisters_significant_donee.remove(ele)\n",
    "            for ele in significative_donee:\n",
    "                if ele in sisters_significant_donee:\n",
    "                    sisters_significant_donee.remove(ele)\n",
    "\n",
    "            if verbose: print(\"donor: \", donor)\n",
    "            if verbose: print(\"significative donee: \", significative_donee)\n",
    "            \n",
    "            \n",
    "            in_clade_significants = []\n",
    "            \n",
    "            ## Test shared ancestry\n",
    "            #Do nested test having two fixed elements, donor and one donee (being this one the significant_donee)\n",
    "            #Assumption: if a vs b is significant, that significancy will maintain if we do a test involving\n",
    "            #a vs b vs b_sister. If b significancy is lost, return it as false positive.\n",
    "            if len(sisters_significant_donee) > 0:\n",
    "                \n",
    "                \n",
    "                if verbose: print(\"--- Testing against sisters: \", sisters_significant_donee, \"---\")\n",
    "                \n",
    "                #Test against all sisters\n",
    "                for sister in sisters_significant_donee:\n",
    "                    s_sd = str(sorted([sister, *significative_donee]))\n",
    "                    \n",
    "                    \n",
    "\n",
    "                    #Check if the test was already performed to skip it\n",
    "                    if s_sd not in tests_performed_dict[str(*donor)].keys():\n",
    "                        # Create the test\n",
    "                        in_clade_test = {\"p1\":significative_donee,\"p2\":[sister],\"p3\":donor,\"p4\":outgroup}\n",
    "                        \n",
    "                        # Do a baba for the test\n",
    "                        n_tests += 1\n",
    "                        try:\n",
    "                            in_clade_df_result = data.run_test(in_clade_test, nboots=100, quiet=True)\n",
    "                        except:\n",
    "                            continue\n",
    "                        \n",
    "                        \n",
    "                        # If donee 2 is significant, save in performed test and add this result to the clade\n",
    "                        if in_clade_df_result[\"Z\"].values[0] > zscoreTH:\n",
    "                            in_clade_sd = get_significant_donee(in_clade_df_result, in_clade_test)\n",
    "#                             tests_performed_dict[str(*donor)][s_sd] = str(*in_clade_sd) #ToDo, this registry can include untested significants\n",
    "                            \n",
    "                            #Add to a list of significants in the clade, if more than one is in this list shared ancestry could be true\n",
    "                            if in_clade_sd not in in_clade_significants:\n",
    "                                in_clade_significants.append(str(*in_clade_sd))\n",
    "                                          \n",
    "                            if verbose: print(\"- significative donee found for\", s_sd, \": \", str(*in_clade_sd))\n",
    "                        else:\n",
    "                            in_clade_sd = None\n",
    "                            tests_performed_dict[str(*donor)][s_sd] = None\n",
    "                            if verbose: print(\"- no significative donee found in\", s_sd)\n",
    "                        \n",
    "                    else:\n",
    "                        #If test was already done, just copy the result\n",
    "                        in_clade_sd = tests_performed_dict[str(*donor)][s_sd]\n",
    "                        if verbose: print(\"- test already performed (skipped) \" + s_sd + \". Previous significative donee: \", tests_performed_dict[str(*donor)][s_sd])\n",
    "                        #If result is different to None add it to in_clade_significants for further interpretation\n",
    "                        if in_clade_sd:\n",
    "                            if in_clade_sd not in in_clade_significants:\n",
    "                                in_clade_significants.append(in_clade_sd)\n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            \n",
    "            else:\n",
    "                #If no more sisters in the clade because all of them were included in the main test.\n",
    "                #For now it is assumed as false positive. ToDo: explore more about it.\n",
    "#                 if verbose: print(\"All sisters already in the test\")\n",
    "                if verbose: print(\"Shared ancestry or too close related, assumed as false positive\")\n",
    "#                 if str(*significative_donee) not in in_clade_significants:\n",
    "#                     in_clade_significants.append(str(*significative_donee))\n",
    "                    \n",
    "                    \n",
    "            ## Decision maker\n",
    "            # Based on in_clade_significants results in previous steps (a.k.a. true positives for verification) do               \n",
    "            if verbose: print(\"in_clade_significants\", in_clade_significants)\n",
    "                \n",
    "            if in_clade_significants:\n",
    "                if str(*significative_donee) in in_clade_significants:\n",
    "                    if len(in_clade_significants) > 1:\n",
    "                        if verbose: print(\"shared true\")\n",
    "                        #ToDo: maybe return ancestral node instead of tip in tree. Do some simulations with this scenario\n",
    "                    else:\n",
    "                        if verbose: print(\"true positive for verification\")\n",
    "                    \n",
    "#                    \n",
    "                    \n",
    "                    ## Distance test: despite there is some true positive, it still may be false negative. For example\n",
    "                    # tests where the pair compared are very distant from the donor, so any minimal\n",
    "                    # allele frequency common in both may be give this false result\n",
    "                    # Using sister as outgroups and put the outgroup as pair, I induce a max distancing distorion\n",
    "                    # if it pass, true positive is verified, if not, it may be a artifact caused by distance\n",
    "                    #distant test to reduce false positives caused by distant samples\n",
    "                    if distant:\n",
    "                        sisters_donor = tree.get_tip_labels(tree.idx_dict[tree.get_mrca_idx_from_tip_labels(donor)].get_ancestors()[0].idx) \n",
    "                        #remove donor from sister group\n",
    "                        if str(*donor) in sisters_donor:\n",
    "                            sisters_donor.remove(str(*donor))\n",
    "                        \n",
    "                        #remove significant donee from sister group\n",
    "#                         if str(*in_clade_significants) in sisters_donor:\n",
    "#                             sisters_donor.remove(str(*in_clade_significants))\n",
    "                        #correct bug in case in_clade_significants is more than one elment\n",
    "                        for ics in in_clade_significants:\n",
    "                            if ics in sisters_donor:\n",
    "                                sisters_donor.remove(ics)\n",
    "\n",
    "\n",
    "                        #if still something is in sisters_donor group do distant test\n",
    "                        if sisters_donor:\n",
    "\n",
    "                            #Create distant test\n",
    "                            distant_test = {\"p1\":outgroup,\"p2\":in_clade_significants,\"p3\":donor,\"p4\":sisters_donor}\n",
    "                            if verbose: print(\">>> distant test to verify significant donee:\", distant_test, \"<<<\")\n",
    "\n",
    "                            #Do distant test\n",
    "                            n_tests += 1\n",
    "                            try:\n",
    "                                distant_df_result = data.run_test(distant_test, nboots=100, quiet=True)\n",
    "                            except:\n",
    "#                                 print(\"fail in distant\")\n",
    "                                truepositives_network.append((*donor, *in_clade_significants))\n",
    "                                break\n",
    "\n",
    "\n",
    "\n",
    "                           \n",
    "                            if distant_df_result[\"Z\"].values[0] > zscoreTH:\n",
    "                                distant_sd = get_significant_donee(distant_df_result, distant_test)\n",
    "                                if distant_sd == in_clade_significants:\n",
    "                                    if (*donor, *in_clade_significants) not in truepositives_network:\n",
    "                                        truepositives_network.append((*donor, *in_clade_significants))\n",
    "                                    if verbose: print(\"true verified\", distant_sd)\n",
    "                                else:\n",
    "                                    if verbose: print(\"falsed by distance\", distant_sd)\n",
    "                                    n_fp += 1\n",
    "                            else:\n",
    "                                if verbose: print(\"no signficant in this test true positive rejected\")\n",
    "                                n_fp += 1\n",
    "\n",
    "                        # when no sisters to tests distance bias do\n",
    "                        else:\n",
    "                            if verbose: print(\"imposible to do distant tests\") #significant donnee assummed as false positive\")\n",
    "    #                         if (*donor, *in_clade_significants) not in truepositives_network:\n",
    "    #                             truepositives_network.append((*donor, *in_clade_significants))\n",
    "                    else:\n",
    "                         truepositives_network.append((*donor, *in_clade_significants))\n",
    "                        \n",
    "                \n",
    "\n",
    "\n",
    "\n",
    "                else:\n",
    "                    if verbose: print(\"false but others in the clade?\")\n",
    "                    n_fp += 1\n",
    "                    \n",
    "                    \n",
    "            else:\n",
    "                if verbose: print(\"false\")\n",
    "                n_fp += 1\n",
    "                    \n",
    "            \n",
    "            \n",
    "        \n",
    "        \n",
    "        #No significant result in test\n",
    "        else:\n",
    "            if verbose: print(\"No significant donee in test\")\n",
    "            tests_performed_dict[str(*donor)][str(sorted(donees))] = None\n",
    "    \n",
    "    if verbose: print (\"\\nNumber of tests performed:\" + str(n_tests))\n",
    "    if verbose: print (\"False positives depured:\" + str(n_fp))\n",
    "#     if verbose: print (tests_performed_dict)\n",
    "    return truepositives_network"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "#Define number of edges\n",
    "edges = 3\n",
    "\n",
    "#Define number of tips and scenarios\n",
    "tips = 20\n",
    "scenarios = 100\n",
    "\n",
    "#Define outgroup\n",
    "outgroup = \"r19\""
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": []
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Create scenarios"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "wrote 93191 SNPs to /home/carlos/AutoABBA/scene_3/test-baba-miss50_0_7to13and10to16and5to18.snps.hdf5\n",
      "wrote 93445 SNPs to /home/carlos/AutoABBA/scene_3/test-baba-miss50_1_11to12and10to1and15to7.snps.hdf5\n",
      "wrote 92957 SNPs to /home/carlos/AutoABBA/scene_3/test-baba-miss50_2_12to1and4to11and10to5.snps.hdf5\n",
      "wrote 93148 SNPs to /home/carlos/AutoABBA/scene_3/test-baba-miss50_3_2to14and7to3and13to11.snps.hdf5\n",
      "wrote 93253 SNPs to /home/carlos/AutoABBA/scene_3/test-baba-miss50_4_5to4and12to14and16to7.snps.hdf5\n",
      "wrote 92906 SNPs to /home/carlos/AutoABBA/scene_3/test-baba-miss50_5_1to16and18to5and14to17.snps.hdf5\n",
      "wrote 93083 SNPs to /home/carlos/AutoABBA/scene_3/test-baba-miss50_6_12to5and17to6and16to8.snps.hdf5\n",
      "wrote 93258 SNPs to /home/carlos/AutoABBA/scene_3/test-baba-miss50_7_18to17and15to14and7to13.snps.hdf5\n",
      "wrote 93045 SNPs to /home/carlos/AutoABBA/scene_3/test-baba-miss50_8_5to13and12to8and15to0.snps.hdf5\n",
      "wrote 93042 SNPs to /home/carlos/AutoABBA/scene_3/test-baba-miss50_9_12to6and7to3and11to14.snps.hdf5\n"
     ]
    }
   ],
   "source": [
    "#Create scenarios\n",
    "\n",
    "#Define number of edges\n",
    "edges = 3\n",
    "\n",
    "#Define number of tips and scenarios\n",
    "tips = 20\n",
    "scenarios = 100\n",
    "\n",
    "#Define outgroup\n",
    "outgroup = \"r19\"\n",
    "\n",
    "#Name the scenario\n",
    "name = f\"scene_{edges}\"\n",
    "\n",
    "os.mkdir(f\"/home/carlos/AutoABBA/{name}/\")\n",
    "\n",
    "# generate a balance tree\n",
    "tree = toytree.rtree.baltree(ntips=tips, treeheight=10e6)\n",
    "\n",
    "for scenario in range(scenarios):\n",
    "   \n",
    "    #select two random tips\n",
    "    random_tips = random.sample(range(tips-1), edges * 2)\n",
    "    random_edges = [(random_tips[x], random_tips[x+1], 0.5, 0.15) for x in range(0, edges * 2, 2)]\n",
    "\n",
    "    # create a simulation model for this tree/network: (src, dest, time-prop., admix-prop.)\n",
    "    model = ipcoal.Model(tree=tree, nsamples=2, Ne=4e5, admixture_edges=random_edges)\n",
    "\n",
    "    # simulate N loci\n",
    "    model.sim_loci(nloci=3000, nsites=50)\n",
    "\n",
    "    # drop 50% as missing\n",
    "    model.apply_missing_mask(0.5)\n",
    "\n",
    "    # write result to a database file\n",
    "    part_name = \"and\".join([f\"{random_tips[x]}to{random_tips[x+1]}\" for x in range(0, edges * 2, 2)]) \n",
    "    model.write_snps_to_hdf5(name=f\"{name}/test-baba-miss50_{scenario}_{part_name}\", diploid=True)"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Start parallel engines"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 61,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 61,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "os.system('/bin/bash -c \"ipcluster start --n=3 & \"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 73,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "0"
      ]
     },
     "execution_count": 73,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "## to cancel ipycluster when work is finished\n",
    "os.system('/bin/bash -c \"ipcluster stop\"')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 63,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "[0, 1, 2]"
      ]
     },
     "execution_count": 63,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "ipyclient = ipp.Client()\n",
    "ipyclient.ids"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 67,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AsyncResult: _push>"
      ]
     },
     "execution_count": 67,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "#Share K, functions, and others with all the engines\n",
    "ipyclient[:].push(dict(\n",
    "    generate_tests_from_names=generate_tests_from_names,\n",
    "    edges=edges,\n",
    "    outgroup=outgroup,\n",
    "))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 68,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%px\n",
    "import ipyrad.analysis as ipa\n",
    "import toytree\n",
    "import toyplot\n",
    "import pandas as pd\n",
    "import random\n",
    "import os"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run full filter"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 69,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AsyncResult: execute>"
      ]
     },
     "execution_count": 69,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%px --targets 0 --noblock\n",
    "\n",
    "arr = os.listdir(f\"/home/carlos/AutoABBA/scene_{edges}/\")\n",
    "\n",
    "tips=20\n",
    "tree = toytree.rtree.baltree(ntips=tips, treeheight=10e6)\n",
    "\n",
    "final_result = []\n",
    "\n",
    "for hdf5 in arr: \n",
    "    \n",
    "    trues = [i.split(\"to\") for i in hdf5.split(\"_\")[2].split(\".\")[0].split(\"and\")]\n",
    "    test_id = hdf5.split(\"_\")[1]\n",
    "    \n",
    "    print (test_id)\n",
    "    \n",
    "    baba = ipa.baba21(f\"/home/carlos/AutoABBA/scene_{edges}/{hdf5}\")\n",
    "    source = tree.get_tip_labels()\n",
    "    targets = tree.get_tip_labels()\n",
    "#     outgroup = \"r19\"\n",
    "\n",
    "    tests = generate_tests_from_names(source, targets, outgroup, no_repeat=False)\n",
    "\n",
    "\n",
    "    result = run_tests_depuring(baba, tests, tree, verbose=False, distant=True)\n",
    "\n",
    "#     print([test_id, trueSource, trueTarget, result])\n",
    "#     final_result.append([test_id, trueSource, trueTarget, result])\n",
    "#     print(result)\n",
    "#     with open(\"fulldepur.txt\", \"a\") as f:\n",
    "#         f.write(str([test_id, trueSource, trueTarget, result])+ \"\\n\")\n",
    "    file = open(f\"fulldepur_s{edges}.txt\", \"a\")\n",
    "    file.write(str([test_id, trues, result])+ \"\\n\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run filter without distant bias test"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 70,
   "metadata": {
    "scrolled": false
   },
   "outputs": [
    {
     "data": {
      "text/plain": [
       "<AsyncResult: execute>"
      ]
     },
     "execution_count": 70,
     "metadata": {},
     "output_type": "execute_result"
    }
   ],
   "source": [
    "# %%px --targets 1 --noblock\n",
    "\n",
    "\n",
    "\n",
    "arr = os.listdir(f\"/home/carlos/AutoABBA/scene_{edges}/\")\n",
    "\n",
    "tips=20\n",
    "tree = toytree.rtree.baltree(ntips=tips, treeheight=10e6)\n",
    "\n",
    "final_result = []\n",
    "\n",
    "for hdf5 in arr: \n",
    "    \n",
    "    trues = [i.split(\"to\") for i in hdf5.split(\"_\")[2].split(\".\")[0].split(\"and\")]\n",
    "    test_id = hdf5.split(\"_\")[1]\n",
    "    \n",
    "    print (test_id)\n",
    "    \n",
    "    baba = ipa.baba21(f\"/home/carlos/AutoABBA/scene_{edges}/{hdf5}\")\n",
    "    source = tree.get_tip_labels()\n",
    "    targets = tree.get_tip_labels()\n",
    "#     outgroup = \"r19\"\n",
    "\n",
    "    tests = generate_tests_from_names(source, targets, outgroup, no_repeat=False)\n",
    "\n",
    "\n",
    "    result = run_tests_depuring(baba, tests, tree, verbose=False, distant=False)\n",
    "\n",
    "#     print([test_id, trueSource, trueTarget, result])\n",
    "#     final_result.append([test_id, trueSource, trueTarget, result])\n",
    "#     print(result)\n",
    "#     with open(\"fulldepur.txt\", \"a\") as f:\n",
    "#         f.write(str([test_id, trueSource, trueTarget, result])+ \"\\n\")\n",
    "    file = open(f\"fulldepur_s{edges}.txt\", \"a\")\n",
    "    file.write(str([test_id, trues, result])+ \"\\n\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "markdown",
   "metadata": {},
   "source": [
    "## Run pure ABBA-BABA"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": null,
   "metadata": {},
   "outputs": [],
   "source": [
    "%%capture pure\n",
    "\n",
    "arr = os.listdir(f\"/home/carlos/AutoABBA/scene_{edges}/\")\n",
    "\n",
    "tips=20\n",
    "tree = toytree.rtree.baltree(ntips=tips, treeheight=10e6)\n",
    "\n",
    "final_result = []\n",
    "\n",
    "for hdf5 in arr: \n",
    "    \n",
    "#     trueSource, trueTarget = hdf5.split(\"_\")[2].split(\".\")[0].split(\"to\")\n",
    "    trues = [i.split(\"to\") for i in hdf5.split(\"_\")[2].split(\".\")[0].split(\"and\")]\n",
    "    test_id = hdf5.split(\"_\")[1]\n",
    "    \n",
    "    print (test_id)\n",
    "    \n",
    "    baba = ipa.baba21(f\"/home/carlos/AutoABBA/scene_{edges}/{hdf5}\")\n",
    "    source = tree.get_tip_labels()\n",
    "    targets = tree.get_tip_labels()\n",
    "#     outgroup = \"r19\"\n",
    "\n",
    "    tests = generate_tests_from_names(source, targets, outgroup, no_repeat=False)\n",
    "    \n",
    "    result = []\n",
    "    for i in tests:\n",
    "        try:\n",
    "            df = baba.run_test(i, nboots=100, quiet=True)\n",
    "        except:\n",
    "            continue\n",
    "        \n",
    "        if df[\"Z\"].values[0] > 2.5:\n",
    "            pair = (*i[\"p3\"], *get_significant_donee(df, i))\n",
    "            if pair not in result:\n",
    "                result.append(pair)\n",
    "\n",
    "\n",
    "\n",
    "    \n",
    "#     \n",
    "#     print([test_id, trueSource, trueTarget, result])\n",
    "#     final_result.append([test_id, trueSource, trueTarget, result])\n",
    "#     print(result)\n",
    "#     with open(\"fulldepur.txt\", \"a\") as f:\n",
    "#         f.write(str([test_id, trueSource, trueTarget, result])+ \"\\n\")\n",
    "    file = open(f\"pureabbababa_s{edges}.txt\", \"a\")\n",
    "    file.write(str([test_id, trues, result])+ \"\\n\")\n",
    "    file.close()"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 72,
   "metadata": {},
   "outputs": [
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "1\n"
     ]
    }
   ],
   "source": [
    "print(1)"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3.7.6 64-bit ('anaconda3': virtualenv)",
   "language": "python",
   "name": "python37664bitanaconda3virtualenv32f24a90012d4dbfb1dfe352b229909b"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.7.6"
  },
  "toc": {
   "base_numbering": 1,
   "nav_menu": {},
   "number_sections": true,
   "sideBar": true,
   "skip_h1_title": false,
   "title_cell": "Table of Contents",
   "title_sidebar": "Contents",
   "toc_cell": false,
   "toc_position": {},
   "toc_section_display": true,
   "toc_window_display": false
  }
 },
 "nbformat": 4,
 "nbformat_minor": 4
}
